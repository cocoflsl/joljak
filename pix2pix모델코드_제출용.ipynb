{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWmGU2WWT438IQgg3+fS99"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iS5zBCHQEt6W"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import cv2\n",
        "from keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import numpy as np\n",
        "from utils import config\n",
        "\n",
        "def get_img_for_model(img_filepath):\n",
        "    img = load_img(img_filepath, target_size=(config.IMG_HEIGHT, config.IMG_WIDTH))\n",
        "    img = np.array(img)\n",
        "    img = (img - 127.5) / 127.5\n",
        "    return img\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, source_dir, target_dir, batch_size, is_training):\n",
        "        self.source_dir = source_dir\n",
        "        self.target_dir = target_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.is_training = is_training\n",
        "\n",
        "        self.img_filenames = self._get_img_filenames(source_dir)\n",
        "        if self.is_training:\n",
        "            np.random.shuffle(self.img_filenames)\n",
        "        else:\n",
        "            self.img_filenames = np.sort(self.img_filenames)\n",
        "\n",
        "    def __getitem__(self, batch_num):\n",
        "        n_imgs = len(self.img_filenames)\n",
        "        idx_start = batch_num * self.batch_size\n",
        "        idx_end = min((batch_num+1) * self.batch_size, n_imgs)\n",
        "        img_filenames_batch = self.img_filenames[idx_start:idx_end]\n",
        "        imgs_source, imgs_target, discriminator_labels_real, discriminator_labels_fake = self._get_batch(img_filenames_batch)\n",
        "\n",
        "        return imgs_source, imgs_target, discriminator_labels_real, discriminator_labels_fake\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.img_filenames) / self.batch_size))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.is_training:\n",
        "            np.random.shuffle(self.img_filenames)\n",
        "\n",
        "    def _draw_color_circles_on_src_img(self, img_src, img_target):\n",
        "        non_white_coords = self._get_non_white_coordinates(img_target)\n",
        "        for center_y, center_x in non_white_coords:\n",
        "            self._draw_color_circle_on_src_img(img_src, img_target, center_y, center_x)\n",
        "\n",
        "    def _draw_color_circle_on_src_img(self, img_src, img_target, center_y, center_x):\n",
        "        y0, y1, x0, x1 = self._get_color_point_bbox_coords(center_y, center_x)\n",
        "        color = np.mean(img_target[y0:y1, x0:x1], axis=(0, 1))\n",
        "        img_src[y0:y1, x0:x1] = color\n",
        "\n",
        "    def _get_batch(self, img_filenames_batch):\n",
        "        batch_size = len(img_filenames_batch)\n",
        "        batch_shape = (batch_size,) + config.IMG_SHAPE\n",
        "        img_sources = np.empty(batch_shape)\n",
        "        img_targets = np.empty(batch_shape)\n",
        "\n",
        "        for idx, img_filename in enumerate(img_filenames_batch):\n",
        "            img_source, img_target = self._get_img_source_and_img_target(img_filename)\n",
        "            img_sources[idx] = img_source\n",
        "            img_targets[idx] = img_target\n",
        "\n",
        "        discriminator_labels_real = self._get_discriminator_labels_real(batch_size)\n",
        "        discriminator_labels_fake = self._get_discriminator_labels_fake(batch_size)\n",
        "\n",
        "        return img_sources, img_targets, discriminator_labels_real, discriminator_labels_fake\n",
        "\n",
        "    def _get_color_point_bbox_coords(self, center_y, center_x):\n",
        "        radius = config.USER_COLOR_POINTS_RADIUS\n",
        "        y0 = max(0, center_y-radius+1)\n",
        "        y1 = min(config.IMG_HEIGHT, center_y+radius)\n",
        "        x0 = max(0, center_x-radius+1)\n",
        "        x1 = min(config.IMG_WIDTH, center_x+radius)\n",
        "\n",
        "        return y0, y1, x0, x1\n",
        "\n",
        "    def _get_discriminator_labels_fake(self, batch_size):\n",
        "        return np.zeros((batch_size, config.IMG_PATCH_HEIGHT, config.IMG_PATCH_WIDTH, 1))\n",
        "\n",
        "    def _get_discriminator_labels_real(self, batch_size):\n",
        "        return np.ones((batch_size, config.IMG_PATCH_HEIGHT, config.IMG_PATCH_WIDTH, 1))\n",
        "\n",
        "    def _get_img_filenames(self, directory):\n",
        "        return [os.path.basename(fp) for fp in glob.glob(f'{directory}/bottomwear_pants*.png')] # jpg > png 수정\n",
        "\n",
        "    def _get_img_source_and_img_target(self, img_filename):\n",
        "        img_source = get_img_for_model(os.path.join(self.source_dir, img_filename))\n",
        "        img_target = get_img_for_model(os.path.join(self.target_dir, img_filename))\n",
        "\n",
        "        if self.is_training:\n",
        "            self._draw_color_circles_on_src_img(img_source, img_target)\n",
        "            # data augmentation\n",
        "            if np.random.random_sample() > 0.5:\n",
        "                img_source = np.fliplr(img_source)\n",
        "                img_target = np.fliplr(img_target)\n",
        "\n",
        "        return img_source, img_target\n",
        "\n",
        "    def _get_non_white_coordinates(self, img):\n",
        "        non_white_mask = np.sum(img, axis=-1) < 2.75\n",
        "        non_white_y, non_white_x = np.nonzero(non_white_mask)\n",
        "\n",
        "        # randomly sample non-white coordinates\n",
        "        n_non_white = len(non_white_y)\n",
        "        n_color_points = min(n_non_white, config.USER_COLOR_POINTS_PER_IMG)\n",
        "        idxs = np.random.choice(n_non_white, n_color_points, replace=False)\n",
        "        non_white_coords = zip(non_white_y[idxs], non_white_x[idxs])\n",
        "\n",
        "        return non_white_coords"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(gen_model, d_model, gan_model, training_generator, validation_generator=None,\n",
        "          epochs = 70, initial_epoch=0, ck_pt_freq=5, output_dir='output', save_models=True):\n",
        "    for epoch_num in tqdm(range(initial_epoch, epochs)):\n",
        "        for imgs_source, imgs_target_real, d_labels_real, d_labels_fake in training_generator:\n",
        "            imgs_target_fake = gen_model.predict(imgs_source)\n",
        "\n",
        "            # update discriminator\n",
        "            d_loss_real = d_model.train_on_batch([imgs_source, imgs_target_real], d_labels_real)\n",
        "            d_loss_fake = d_model.train_on_batch([imgs_source, imgs_target_fake], d_labels_fake)\n",
        "\n",
        "            # update generator\n",
        "            g_loss, _, _ = gan_model.train_on_batch(imgs_source, [d_labels_real, imgs_target_real])\n",
        "\n",
        "        if epoch_num % 3 == 0:\n",
        "            gen_model.save_weights('/content/drive/MyDrive/졸업프로젝트/model_save/gen_bottom_' + str(epoch_num) + '.h5')\n",
        "            dis_model.save_weights('/content/drive/MyDrive/졸업프로젝트/model_save/dis_bottom_' + str(epoch_num) + '.h5')\n",
        "            gan_model.save_weights('/content/drive/MyDrive/졸업프로젝트/model_save/gan_bottom_' + str(epoch_num) + '.h5')\n",
        "\n",
        "        training_generator.on_epoch_end()"
      ],
      "metadata": {
        "id": "tgWVVzOLExnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_dir = '/content/drive/MyDrive/졸업프로젝트/bottom_edge'\n",
        "target_dir = '/content/drive/MyDrive/졸업프로젝트/bottom_data'\n",
        "\n",
        "training_generator = DataGenerator(source_dir, target_dir, 4, is_training = True)"
      ],
      "metadata": {
        "id": "rmlyWUzCEypy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_model = get_generator_model()\n",
        "dis_model = get_discriminator_model()\n",
        "gan_model = get_gan_model(gen_model, dis_model)"
      ],
      "metadata": {
        "id": "RzDCFEsMEzr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(gen_model, dis_model, gan_model, training_generator, epochs = 10)"
      ],
      "metadata": {
        "id": "wm6ugE45E1h1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_model.save('/content/drive/MyDrive/졸업프로젝트/model_save/gen_model_bottomwear.h5')\n",
        "dis_model.save('/content/drive/MyDrive/졸업프로젝트/model_save/dis_model_bottomwear.h5')\n",
        "gan_model.save('/content/drive/MyDrive/졸업프로젝트/model_save/gan_model_bottomwear.h5')"
      ],
      "metadata": {
        "id": "tzNg8XLUE2jK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_img_for_model(img_filepath):\n",
        "    img = load_img(img_filepath, target_size=(config.IMG_HEIGHT, config.IMG_WIDTH))\n",
        "    img = np.array(img)\n",
        "    img = (img - 127.5) / 127.5\n",
        "    return img"
      ],
      "metadata": {
        "id": "ZPuD0RRGE3L4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_source = get_img_for_model('/content/drive/MyDrive/test_bottom.png')\n",
        "imgs_source = np.array([img_source])\n",
        "imgs_target_fake = gen_model_bottom.predict(imgs_source)\n",
        "imgs_target_fake = (imgs_target_fake + 1) / 2.0\n",
        "img_target_fake = imgs_target_fake[0]\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.axis('off')\n",
        "plt.imshow((img_target_fake*255).astype(np.uint8))"
      ],
      "metadata": {
        "id": "TLkRdiTJE4NX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}